LFU和FIFO 算法待研究

缓存的大小是有限的

#### Least Recently Used(最近最少使用算法)

LRU提供的思路是将最近没有使用的数据从缓存中移除

LRU算法的原理比较简单，数据存储的数据结构为链表。当访问数据时，如缓存中有数据，

则将该数据移动至链表的顶端；没有该数据则在顶端加入该数据，并移除链表中的低端的数据。

LRU涉及一个概念叫做缺页中断，缺页中断的次数即一次访问过程时没有没有在缓存中找到数据。



我们看一段经典的带缓存和数据库的数据保存和数据读取的代码

```
// WriteTd stores a block's total difficulty into the database, also caching it
// along the way.
func (hc *HeaderChain) WriteTd(hash common.Hash, number uint64, td *big.Int) error {
	//写时，先写库，后写缓存
	rawdb.WriteTd(hc.chainDb, hash, number, td)
	hc.tdCache.Add(hash, new(big.Int).Set(td))
	return nil
}
func (hc *HeaderChain) GetTd(hash common.Hash, number uint64) *big.Int {
	//读时，先读缓存，数据不存在则读库，再缓存
	// Short circuit if the td's already in the cache, retrieve otherwise
	if cached, ok := hc.tdCache.Get(hash); ok {
		return cached.(*big.Int)
	}
	td := rawdb.ReadTd(hc.chainDb, hash, number)
	if td == nil {
		return nil
	}
	// Cache the found body for next time and return
	hc.tdCache.Add(hash, td)
	return td
}
```

